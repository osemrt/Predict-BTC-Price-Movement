{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '../../dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news = pd.read_csv(dataset_path + '/news/news [only_date].csv')\n",
    "df_price = pd.read_csv(dataset_path + '/price/btc_usd_daily.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17047, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check whether each element in the df_news matches an element in the df_price\n",
    "df_news[df_news.date.isin(df_price.date)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the unncessary features\n",
    "df_new_price = df_price.drop(['close', 'high', 'low', 'change', 'volume', 'market_cap'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the difference in opening prices between the following and current day.\n",
    "df_diff_price = df_new_price.set_index('date').diff(periods=1)\n",
    "df_diff_price['date'] = df_diff_price.index\n",
    "df_diff_price = df_diff_price.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff_price = df_diff_price.rename(columns={'open': 'change_in_open'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>change_in_open</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-605.27</td>\n",
       "      <td>2020-03-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>354.19</td>\n",
       "      <td>2020-03-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.96</td>\n",
       "      <td>2020-03-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-14.87</td>\n",
       "      <td>2020-03-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   change_in_open        date\n",
       "0             NaN  2020-03-24\n",
       "1         -605.27  2020-03-23\n",
       "2          354.19  2020-03-22\n",
       "3           20.96  2020-03-21\n",
       "4          -14.87  2020-03-20"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_diff_price.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>change_in_open</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-605.27</td>\n",
       "      <td>2020-03-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>354.19</td>\n",
       "      <td>2020-03-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.96</td>\n",
       "      <td>2020-03-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-14.87</td>\n",
       "      <td>2020-03-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-946.23</td>\n",
       "      <td>2020-03-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   change_in_open        date\n",
       "1         -605.27  2020-03-23\n",
       "2          354.19  2020-03-22\n",
       "3           20.96  2020-03-21\n",
       "4          -14.87  2020-03-20\n",
       "5         -946.23  2020-03-19"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove top row since it has a null value\n",
    "df_diff_price = df_diff_price[df_diff_price['change_in_open'].notnull()]\n",
    "df_diff_price.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of the opening prices and their corresponding daily headlines from the news\n",
    "changes = []\n",
    "headlines = []\n",
    "\n",
    "for row in df_diff_price.iterrows():\n",
    "\n",
    "    daily_headlines = []\n",
    "    \n",
    "    date = row[1]['date']\n",
    "    change_in_open = row[1]['change_in_open']\n",
    "    \n",
    "    changes.append(change_in_open)\n",
    "\n",
    "    for news_row in df_news[df_news['date'] == date].iterrows():\n",
    "        headline = news_row[1]['headline']\n",
    "        daily_headlines.append(headline)\n",
    "        \n",
    "    # Track progress\n",
    "    headlines.append(daily_headlines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# A list of contractions from http://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python\n",
    "contractions = { \n",
    "\"ain't\": \"am not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"needn't\": \"need not\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there had\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who's\": \"who is\",\n",
    "\"won't\": \"will not\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you're\": \"you are\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text, remove_stopwords = True):\n",
    "    '''Remove unwanted characters and format the text to create fewer nulls word embeddings'''\n",
    "    \n",
    "    # Convert words to lower case\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Replace contractions with their longer forms \n",
    "    if True:\n",
    "        text = text.split()\n",
    "        new_text = []\n",
    "        for word in text:\n",
    "            if word in contractions:\n",
    "                new_text.append(contractions[word])\n",
    "            else:\n",
    "                new_text.append(word)\n",
    "        text = \" \".join(new_text)\n",
    "    \n",
    "    # Format words and remove unwanted characters\n",
    "    text = re.sub(r'&amp;', '', text) \n",
    "    text = re.sub(r'0,0', '00', text) \n",
    "    text = re.sub(r'[_\"\\-;%()|.,+&=*%.,!?:#@\\[\\]]', ' ', text)\n",
    "    text = re.sub(r'\\'', ' ', text)\n",
    "    text = re.sub(r'\\$', ' $ ', text)\n",
    "    text = re.sub(r'j k ', ' jk ', text)\n",
    "    text = re.sub(r' s ', ' ', text)\n",
    "    text = re.sub(r' yr ', ' year ', text)\n",
    "    text = re.sub(r' l g b t ', ' lgbt ', text)\n",
    "    \n",
    "    # Optionally, remove stop words\n",
    "    if remove_stopwords:\n",
    "        text = text.split()\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        text = [w for w in text if not w in stops]\n",
    "        text = \" \".join(text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the headlines\n",
    "cleaned_headlines = []\n",
    "\n",
    "for daily_headlines in headlines:\n",
    "    cleaned_daily_headlines = []\n",
    "    for headline in daily_headlines:\n",
    "        cleaned_daily_headlines.append(clean_text(headline))\n",
    "    cleaned_headlines.append(cleaned_daily_headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rare bitcoin price chart pattern may cryptocurrency’s last hope',\n",
       " 'want sell bitcoin btc $ 6k charts show could ultimate bottom',\n",
       " 'bitcoin price drops $ 3 637 rebounds $ 5 200 within minutes',\n",
       " 'don’t panic previously impervious support could save bitcoin',\n",
       " 'bitcoin crashes $ 7 000 peter schiff calls btc sinking ship',\n",
       " 'nouriel roubini says bitcoin btc zero hedge value price crashes $ 5k',\n",
       " 'analyst “least riskiest” time buy bitcoin',\n",
       " 'bitcoin btc trader mati greenspan sells atcoins',\n",
       " 'top analyst claims bitcoin bottom close here’s trend watch',\n",
       " 'crypto king barry silbert says buys bitcoin btc google trends show alone',\n",
       " 'trading legend peter brandt called worst bitcoin btc price crash since 2013',\n",
       " 'bitcoin decent full hedge fundstrat’s lee',\n",
       " 'bitcoin $ 1k possible warns veteran trader peter brandt',\n",
       " 'mike novogratz says confidence bitcoin btc evaporated',\n",
       " 'bitcoin carving short term bottom near $ 4k massive 50 decline',\n",
       " 'first time i’ve wanted buy bitcoin btc edward snowden',\n",
       " 'analyst predicted bitcoin’s $ 3 000 bottom thinks price action next',\n",
       " 'makeup mogul michelle phan’s coronavirus strategy educate hodl bitcoin',\n",
       " 'amid market downturn number people owning 1 btc hits new record']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_headlines[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dictionary(dictionary, n=5):\n",
    "    i = 0\n",
    "    keys = dictionary.keys()\n",
    "    keys = list(keys)\n",
    "    while (i < len(keys)) and (i < n):\n",
    "        key = keys[i]\n",
    "        value = dictionary[key]\n",
    "        print(\"'{}': {}\".format(key, value))\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Vocabulary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size of the vocabulary is 16089.\n"
     ]
    }
   ],
   "source": [
    "# Find the number of times each word was used and the size of the vocabulary\n",
    "word_counts = {}\n",
    "\n",
    "for daily_headlines in cleaned_headlines:\n",
    "    for headline in daily_headlines:\n",
    "        for word in headline.split():\n",
    "            if word not in word_counts:\n",
    "                word_counts[word] = 1\n",
    "            else:\n",
    "                word_counts[word] += 1\n",
    "\n",
    "print(\"the size of the vocabulary is {}.\".format(len(word_counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'bitcoin': 9020\n",
      "'risks': 54\n",
      "'falling': 31\n",
      "'$': 3361\n",
      "'2': 194\n"
     ]
    }
   ],
   "source": [
    "print_dictionary(word_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Pre-trained Word Embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Glove's embeddings\n",
    "glove_word_vectors = {}\n",
    "\n",
    "with open('./glove.840B.300d.txt', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        values = line.split(' ')\n",
    "        \n",
    "        word = values[0]\n",
    "        word_vector = np.asarray(values[1:], dtype='float32')\n",
    "        \n",
    "        glove_word_vectors[word] = word_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vector = glove_word_vectors['hello']\n",
    "word_vector.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words missing from GloVe: 11\n",
      "Percent of words that are missing from vocabulary: 0.06999999999999999%\n"
     ]
    }
   ],
   "source": [
    "# Find the number of words that are missing from GloVe, \n",
    "# and are used more than our threshold.\n",
    "\n",
    "missing_words = 0\n",
    "threshold = 100\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    if count > threshold:\n",
    "        if word not in glove_word_vectors:\n",
    "            missing_words += 1\n",
    "            \n",
    "missing_ratio = round(missing_words/len(word_counts),4)*100\n",
    "            \n",
    "print(\"Number of words missing from GloVe:\", missing_words)\n",
    "print(\"Percent of words that are missing from vocabulary: {}%\".format(missing_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the vocab that we will use to words that appear ≥ threshold \n",
    "# or are in GloVe\n",
    "\n",
    "#dictionary to convert words to integers\n",
    "vocab_to_int = {} \n",
    "\n",
    "value = 0\n",
    "for word, count in word_counts.items():\n",
    "    if count >= threshold or word in glove_word_vectors:\n",
    "        vocab_to_int[word] = value\n",
    "        value += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Special tokens that will be added to our vocab\n",
    "codes = [\"<UNK>\",\"<PAD>\"]   \n",
    "\n",
    "# Add codes to vocab\n",
    "for code in codes:\n",
    "    vocab_to_int[code] = len(vocab_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to convert integers to words\n",
    "int_to_vocab = {}\n",
    "for word, value in vocab_to_int.items():\n",
    "    int_to_vocab[value] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'bitcoin': 0\n",
      "'risks': 1\n",
      "'falling': 2\n",
      "'$': 3\n",
      "'2': 4\n"
     ]
    }
   ],
   "source": [
    "print_dictionary(vocab_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Unique Words: 16089\n",
      "Number of Words we will use: 12531\n",
      "Percent of Words we will use: 77.89%\n"
     ]
    }
   ],
   "source": [
    "usage_ratio = round(len(vocab_to_int) / len(word_counts),4)*100\n",
    "\n",
    "print(\"Total Number of Unique Words:\", len(word_counts))\n",
    "print(\"Number of Words we will use:\", len(vocab_to_int))\n",
    "print(\"Percent of Words we will use: {}%\".format(usage_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to use 300 features for embedding dimensions to match Glove's vectors\n",
    "embedding_dimension = 300\n",
    "\n",
    "vocabulary_size = len(vocab_to_int)\n",
    "\n",
    "# Create a matrix with default values of zero\n",
    "word_vectors = {}\n",
    "\n",
    "for word, i in int_to_vocab.items():\n",
    "    if word in glove_word_vectors:\n",
    "        word_vectors[i] = glove_word_vectors[word]\n",
    "    else:\n",
    "        # If word not in GloVe, create a random embedding for it\n",
    "        random_word_vector = np.array(np.random.uniform(-1.0, 1.0, embedding_dimension))\n",
    "        word_vectors[i] = random_word_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12531\n"
     ]
    }
   ],
   "source": [
    "# Check if value matches len(vocab_to_int)\n",
    "print(len(word_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "del glove_word_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Print word_vectors to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.56166086, -0.42181205,  0.4805779 , -0.42246179, -0.26790248,\n",
       "       -0.32090736, -0.91195876, -0.90963409, -0.56749001,  0.94145851,\n",
       "       -0.26286334, -0.34662148,  0.43378484, -0.28257271,  0.26442837,\n",
       "       -0.43119897, -0.55740414, -0.99996626, -0.98631349,  0.63943101,\n",
       "        0.92791511,  0.76446702, -0.91665483,  0.52439546,  0.78965406,\n",
       "        0.81536737,  0.97799683,  0.09204672, -0.55212957,  0.0411007 ,\n",
       "       -0.70615013,  0.21369788,  0.86113296,  0.63482808, -0.30654069,\n",
       "        0.44628239,  0.8688643 ,  0.67241658, -0.58257331,  0.23834374,\n",
       "       -0.7588579 ,  0.16176557, -0.27261337,  0.90107218,  0.26564669,\n",
       "        0.22922821, -0.54029966, -0.76856403, -0.45154211, -0.82929492,\n",
       "       -0.72300173, -0.7331348 ,  0.2440029 ,  0.47966638,  0.80892526,\n",
       "       -0.34214966,  0.31892246,  0.96450976,  0.67479979,  0.46164475,\n",
       "       -0.57025066,  0.03859755, -0.46263229,  0.79078072, -0.28424882,\n",
       "       -0.41528115, -0.11224276,  0.5306735 , -0.87279022, -0.0889662 ,\n",
       "       -0.93925166,  0.78924876, -0.69336388, -0.98625985, -0.37663612,\n",
       "        0.93889554, -0.8788425 ,  0.349511  , -0.82938237, -0.54168239,\n",
       "       -0.93827812,  0.19286268,  0.55201356,  0.07288671,  0.17231798,\n",
       "        0.46059471, -0.93983333,  0.35928673, -0.8251198 ,  0.22204067,\n",
       "        0.52917511, -0.59406121,  0.2025818 ,  0.21177906,  0.37528686,\n",
       "        0.21427985, -0.52350907,  0.77159559, -0.08399684, -0.77864054,\n",
       "        0.9566007 ,  0.63002992,  0.79541833, -0.48245321, -0.91491975,\n",
       "       -0.26523494, -0.4921302 ,  0.90671069,  0.48259085, -0.78417362,\n",
       "        0.53691467, -0.81984833,  0.37834153, -0.3423695 ,  0.35100173,\n",
       "        0.7040264 , -0.8847377 ,  0.28926599, -0.96875186, -0.77170644,\n",
       "        0.71353504, -0.44937479,  0.62438608, -0.22856177, -0.18023554,\n",
       "       -0.91678495, -0.56515565,  0.10735873,  0.47144522, -0.22317022,\n",
       "        0.61238898, -0.00397409, -0.23475173, -0.3499877 , -0.80967188,\n",
       "        0.0742388 ,  0.79205405,  0.15482904, -0.64538861,  0.24998301,\n",
       "        0.7846751 , -0.00971355,  0.47131589, -0.75616843,  0.29223456,\n",
       "       -0.00744202, -0.39244935, -0.74644514,  0.93685388, -0.74329833,\n",
       "        0.42463696,  0.08141318, -0.93533915, -0.15290656,  0.49386454,\n",
       "       -0.2882256 , -0.88521413, -0.76967568,  0.55202288,  0.27270264,\n",
       "        0.53673146, -0.99221023, -0.99655769,  0.13772136, -0.68626875,\n",
       "        0.42389348,  0.14140996,  0.5493896 ,  0.45067424,  0.17045371,\n",
       "       -0.26015845, -0.45429016, -0.20210933, -0.06821591,  0.46468977,\n",
       "       -0.59010533, -0.95488562,  0.82062821, -0.55676562,  0.32154286,\n",
       "        0.61858816,  0.08383278,  0.55524204,  0.96881673,  0.15548798,\n",
       "       -0.65402808, -0.13436109, -0.25825636, -0.26426698, -0.1244196 ,\n",
       "       -0.69927145, -0.84093109, -0.21004111, -0.77863082,  0.98555735,\n",
       "       -0.28358559, -0.165692  ,  0.55014296,  0.09023192,  0.54784004,\n",
       "       -0.69070797, -0.76734289, -0.98294607, -0.54038272,  0.50159613,\n",
       "        0.57822887,  0.76219729, -0.36178585,  0.74363249,  0.28029936,\n",
       "       -0.91648945,  0.41599887,  0.70614707,  0.24401737,  0.81429039,\n",
       "        0.29400786, -0.11921561, -0.10576894,  0.69620029,  0.54936983,\n",
       "       -0.54497878,  0.23303775,  0.24293655,  0.6638334 ,  0.26855378,\n",
       "        0.30807784,  0.67903502,  0.68372201,  0.73524752,  0.30279034,\n",
       "       -0.53254672, -0.73479387, -0.87960462,  0.40834907,  0.72275708,\n",
       "        0.41203203, -0.49361107,  0.28823592, -0.67490209, -0.8779415 ,\n",
       "       -0.11081616,  0.74188774, -0.98721334, -0.19619652, -0.89081376,\n",
       "       -0.03950862,  0.77311525,  0.95998304, -0.94271958, -0.70371558,\n",
       "        0.36459767,  0.19377405, -0.00229519,  0.43177359,  0.68133918,\n",
       "       -0.28364089,  0.7777181 , -0.69988864,  0.95281373, -0.03022229,\n",
       "       -0.21164977, -0.9269106 ,  0.42756966, -0.56093045,  0.58724201,\n",
       "       -0.51622666,  0.74841188, -0.34390608,  0.06756533, -0.6627434 ,\n",
       "        0.96185417, -0.01572931, -0.55642482,  0.58102515,  0.4910415 ,\n",
       "       -0.75768819, -0.36697357, -0.58623121, -0.53474056, -0.23905902,\n",
       "        0.84068762,  0.42572872, -0.18648396, -0.05005879,  0.40013385,\n",
       "        0.65807444,  0.47143666,  0.92316724, -0.30812235,  0.97619238,\n",
       "        0.34425135,  0.14484243, -0.49064828,  0.50870361, -0.50435752,\n",
       "       -0.21290991,  0.27801095, -0.40382556, -0.56535718, -0.83804391])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors['bitcoin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(word_vector, key):\n",
    "    features = []\n",
    "    for feature in word_vector:\n",
    "        features.append(feature)\n",
    "        \n",
    "    return features   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"word_vectors.csv\"\n",
    "csv_columns = ['key', 'vector']\n",
    "with open(csv_file, 'w', newline='', encoding=\"utf-8\") as file:\n",
    "        writer = csv.writer(file, quoting=csv.QUOTE_NONNUMERIC)\n",
    "        writer.writerow(csv_columns)\n",
    "        \n",
    "        for key in word_vectors.keys():\n",
    "            word_vector = word_vectors[key]    \n",
    "            features = get_features(word_vector, key)    \n",
    "            writer.writerow([key, features])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "389px",
    "left": "1550px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
