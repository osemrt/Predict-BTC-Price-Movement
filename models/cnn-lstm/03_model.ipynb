{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dictionary(dictionary, n=5):\n",
    "    i = 0\n",
    "    keys = dictionary.keys()\n",
    "    keys = list(keys)\n",
    "    while (i < len(keys)) and (i < n):\n",
    "        key = keys[i]\n",
    "        value = dictionary[key]\n",
    "        print(\"'{}': {}\".format(key, value))\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot data to see relationship in training and validation data\n",
    "def plot_accuracy(hist):\n",
    "    epoch_list=list(range(1, len(hist.history['accuracy']) + 1)) # values for x axis [1, 2, 3, 4, ..., # of epochs]\n",
    "    plt.plot(epoch_list, hist.history['accuracy'], epoch_list, hist.history['val_accuracy'])\n",
    "    plt.legend(('Training Accuracy', 'Validation Accuracy'))\n",
    "    plt.show()\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importing the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '../../dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news = pd.read_csv(dataset_path + '/news/news [only_date].csv')\n",
    "df_price = pd.read_csv(dataset_path + '/price/btc_usd_daily.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>Bitcoin Risks Falling to $2,900 if Market is H...</td>\n",
       "      <td>https://www.newsbtc.com/2020/03/14/bitcoin-ris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>Here’s Why Bitcoin Didn’t Bottom at $3,800 Acc...</td>\n",
       "      <td>https://www.newsbtc.com/2020/03/15/heres-why-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>Bitcoin Sinks to $4,390 as Dow’s 1,000-Point D...</td>\n",
       "      <td>https://www.newsbtc.com/2020/03/16/bitcoin-sin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>Bitcoin could soon be in the museum of illusio...</td>\n",
       "      <td>https://eng.ambcrypto.com/bitcoin-could-soon-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>Bitcoin Price Analysis: BTC’s 3-Day Consolidat...</td>\n",
       "      <td>https://cryptopotato.com/bitcoin-price-analysi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                           headline  \\\n",
       "0  2020-03-16  Bitcoin Risks Falling to $2,900 if Market is H...   \n",
       "1  2020-03-16  Here’s Why Bitcoin Didn’t Bottom at $3,800 Acc...   \n",
       "2  2020-03-16  Bitcoin Sinks to $4,390 as Dow’s 1,000-Point D...   \n",
       "3  2020-03-16  Bitcoin could soon be in the museum of illusio...   \n",
       "4  2020-03-16  Bitcoin Price Analysis: BTC’s 3-Day Consolidat...   \n",
       "\n",
       "                                              source  \n",
       "0  https://www.newsbtc.com/2020/03/14/bitcoin-ris...  \n",
       "1  https://www.newsbtc.com/2020/03/15/heres-why-b...  \n",
       "2  https://www.newsbtc.com/2020/03/16/bitcoin-sin...  \n",
       "3  https://eng.ambcrypto.com/bitcoin-could-soon-b...  \n",
       "4  https://cryptopotato.com/bitcoin-price-analysi...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17047, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>change</th>\n",
       "      <th>volume</th>\n",
       "      <th>market_cap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-24</td>\n",
       "      <td>6436.64</td>\n",
       "      <td>6734.80</td>\n",
       "      <td>6789.02</td>\n",
       "      <td>6411.07</td>\n",
       "      <td>4.63</td>\n",
       "      <td>48221910672</td>\n",
       "      <td>123148917787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-23</td>\n",
       "      <td>5831.37</td>\n",
       "      <td>6416.31</td>\n",
       "      <td>6443.93</td>\n",
       "      <td>5785.00</td>\n",
       "      <td>10.03</td>\n",
       "      <td>46491916000</td>\n",
       "      <td>117314776187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-22</td>\n",
       "      <td>6185.56</td>\n",
       "      <td>5830.25</td>\n",
       "      <td>6359.70</td>\n",
       "      <td>5823.71</td>\n",
       "      <td>-5.74</td>\n",
       "      <td>40099664740</td>\n",
       "      <td>106591196069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-21</td>\n",
       "      <td>6206.52</td>\n",
       "      <td>6185.07</td>\n",
       "      <td>6378.14</td>\n",
       "      <td>5932.82</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>42494390880</td>\n",
       "      <td>113068192795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>6191.65</td>\n",
       "      <td>6198.78</td>\n",
       "      <td>6844.26</td>\n",
       "      <td>5865.78</td>\n",
       "      <td>0.12</td>\n",
       "      <td>54442976103</td>\n",
       "      <td>113309245860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date     open    close     high      low  change       volume  \\\n",
       "0  2020-03-24  6436.64  6734.80  6789.02  6411.07    4.63  48221910672   \n",
       "1  2020-03-23  5831.37  6416.31  6443.93  5785.00   10.03  46491916000   \n",
       "2  2020-03-22  6185.56  5830.25  6359.70  5823.71   -5.74  40099664740   \n",
       "3  2020-03-21  6206.52  6185.07  6378.14  5932.82   -0.35  42494390880   \n",
       "4  2020-03-20  6191.65  6198.78  6844.26  5865.78    0.12  54442976103   \n",
       "\n",
       "     market_cap  \n",
       "0  123148917787  \n",
       "1  117314776187  \n",
       "2  106591196069  \n",
       "3  113068192795  \n",
       "4  113309245860  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_price.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2522, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_price.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17047, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check whether each element in the df_news matches an element in the df_price\n",
    "df_news[df_news.date.isin(df_price.date)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>change</th>\n",
       "      <th>volume</th>\n",
       "      <th>market_cap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>5385.23</td>\n",
       "      <td>5014.48</td>\n",
       "      <td>5385.23</td>\n",
       "      <td>4575.36</td>\n",
       "      <td>-6.88</td>\n",
       "      <td>45368026430</td>\n",
       "      <td>91633478850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-03-15</td>\n",
       "      <td>5201.07</td>\n",
       "      <td>5392.31</td>\n",
       "      <td>5836.65</td>\n",
       "      <td>5169.28</td>\n",
       "      <td>3.68</td>\n",
       "      <td>33997889639</td>\n",
       "      <td>98530059890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020-03-14</td>\n",
       "      <td>5573.08</td>\n",
       "      <td>5200.37</td>\n",
       "      <td>5625.23</td>\n",
       "      <td>5125.07</td>\n",
       "      <td>-6.69</td>\n",
       "      <td>36154506008</td>\n",
       "      <td>95014981944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>5017.83</td>\n",
       "      <td>5563.71</td>\n",
       "      <td>5838.11</td>\n",
       "      <td>4106.98</td>\n",
       "      <td>10.88</td>\n",
       "      <td>74156772075</td>\n",
       "      <td>101644613038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>7913.62</td>\n",
       "      <td>4970.79</td>\n",
       "      <td>7929.12</td>\n",
       "      <td>4860.35</td>\n",
       "      <td>-37.19</td>\n",
       "      <td>53980357243</td>\n",
       "      <td>90804613601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>1156.73</td>\n",
       "      <td>1013.38</td>\n",
       "      <td>1191.10</td>\n",
       "      <td>910.42</td>\n",
       "      <td>-12.39</td>\n",
       "      <td>510199008</td>\n",
       "      <td>16300254795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>1044.40</td>\n",
       "      <td>1154.73</td>\n",
       "      <td>1159.42</td>\n",
       "      <td>1044.40</td>\n",
       "      <td>10.56</td>\n",
       "      <td>344945984</td>\n",
       "      <td>18571869009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>1021.60</td>\n",
       "      <td>1043.84</td>\n",
       "      <td>1044.08</td>\n",
       "      <td>1021.60</td>\n",
       "      <td>2.18</td>\n",
       "      <td>185168000</td>\n",
       "      <td>16786368910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1177</th>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>998.62</td>\n",
       "      <td>1021.75</td>\n",
       "      <td>1031.39</td>\n",
       "      <td>996.70</td>\n",
       "      <td>2.32</td>\n",
       "      <td>222184992</td>\n",
       "      <td>16429024775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>963.66</td>\n",
       "      <td>998.33</td>\n",
       "      <td>1003.08</td>\n",
       "      <td>958.70</td>\n",
       "      <td>3.60</td>\n",
       "      <td>147775008</td>\n",
       "      <td>16050407461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1128 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date     open    close     high      low  change       volume  \\\n",
       "8     2020-03-16  5385.23  5014.48  5385.23  4575.36   -6.88  45368026430   \n",
       "9     2020-03-15  5201.07  5392.31  5836.65  5169.28    3.68  33997889639   \n",
       "10    2020-03-14  5573.08  5200.37  5625.23  5125.07   -6.69  36154506008   \n",
       "11    2020-03-13  5017.83  5563.71  5838.11  4106.98   10.88  74156772075   \n",
       "12    2020-03-12  7913.62  4970.79  7929.12  4860.35  -37.19  53980357243   \n",
       "...          ...      ...      ...      ...      ...     ...          ...   \n",
       "1174  2017-01-05  1156.73  1013.38  1191.10   910.42  -12.39    510199008   \n",
       "1175  2017-01-04  1044.40  1154.73  1159.42  1044.40   10.56    344945984   \n",
       "1176  2017-01-03  1021.60  1043.84  1044.08  1021.60    2.18    185168000   \n",
       "1177  2017-01-02   998.62  1021.75  1031.39   996.70    2.32    222184992   \n",
       "1178  2017-01-01   963.66   998.33  1003.08   958.70    3.60    147775008   \n",
       "\n",
       "        market_cap  \n",
       "8      91633478850  \n",
       "9      98530059890  \n",
       "10     95014981944  \n",
       "11    101644613038  \n",
       "12     90804613601  \n",
       "...            ...  \n",
       "1174   16300254795  \n",
       "1175   18571869009  \n",
       "1176   16786368910  \n",
       "1177   16429024775  \n",
       "1178   16050407461  \n",
       "\n",
       "[1128 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hold only df_price entries which matches same date interval with df_news\n",
    "df_price = df_price.loc[df_price['date'].isin(df_news['date'])]\n",
    "df_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of daily headlines from the news\n",
    "daily_headlines = []\n",
    "\n",
    "for row in df_price.iterrows():\n",
    "\n",
    "    headlines = []    \n",
    "    date = row[1]['date']\n",
    "\n",
    "    for news_row in df_news[df_news['date'] == date].iterrows():\n",
    "        headline = news_row[1]['headline']\n",
    "        headlines.append(headline)\n",
    "        \n",
    "    # Track progress\n",
    "    daily_headlines.append(headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1128\n",
      "1128\n"
     ]
    }
   ],
   "source": [
    "# Compare lengths to ensure they are the same\n",
    "print(len(df_price))\n",
    "print(len(daily_headlines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bitcoin Risks Falling to $2,900 if Market is Heading for Long-Term lower low',\n",
       " 'Here’s Why Bitcoin Didn’t Bottom at $3,800 According to a Top analyst',\n",
       " 'Bitcoin Sinks to $4,390 as Dow’s 1,000-Point Drop Risks Bigger breakdown',\n",
       " 'Bitcoin could soon be in the museum of illusions: ex Director-General ECB',\n",
       " 'Bitcoin Price Analysis: BTC’s 3-Day Consolidation Is Likely To End By Huge Move Very Soon',\n",
       " '‘Extreme Fear’ Grips Markets Despite Oversold Bitcoin Price Metrics',\n",
       " 'Bitcoin (BTC) Price Bottom Might Be Already In. Trader Explains Why',\n",
       " 'Bitcoin Trading Near Make-or-Break Levels: Can Bulls Make It?',\n",
       " 'Here’s How Bitcoin’s Market Cap Would Look Like in 3D',\n",
       " 'Bitcoin Fails to Jump $6,000, Top Analyst Warns Further Breakdown',\n",
       " '1 of BitMEX’s Most Profitable Traders Still Thinks Bitcoin Will Hit $30,000',\n",
       " 'Bitcoin Mempool Briefly Drops to Zero on Blockchain.\\u200bcom',\n",
       " 'Despite Bitcoin Price Dips, Crypto Is a Safe Haven in the Middle East',\n",
       " 'Bitcoin Price Tops $5.9K as Fed Cuts Interest Rates to 0%, Restarts QE']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_headlines[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# A list of contractions from http://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python\n",
    "contractions = { \n",
    "\"ain't\": \"am not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"needn't\": \"need not\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there had\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who's\": \"who is\",\n",
    "\"won't\": \"will not\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you're\": \"you are\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text, remove_stopwords = True):\n",
    "    '''Remove unwanted characters and format the text to create fewer nulls word embeddings'''\n",
    "    \n",
    "    # Convert words to lower case\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Replace contractions with their longer forms \n",
    "    if True:\n",
    "        text = text.split()\n",
    "        new_text = []\n",
    "        for word in text:\n",
    "            if word in contractions:\n",
    "                new_text.append(contractions[word])\n",
    "            else:\n",
    "                new_text.append(word)\n",
    "        text = \" \".join(new_text)\n",
    "    \n",
    "    # Format words and remove unwanted characters\n",
    "    text = re.sub(r'&amp;', '', text) \n",
    "    text = re.sub(r'0,0', '00', text) \n",
    "    text = re.sub(r'[_\"\\-;%()|.,+&=*%.,!?:#@\\[\\]]', ' ', text)\n",
    "    text = re.sub(r'\\'', ' ', text)\n",
    "    text = re.sub(r'\\$', ' $ ', text)\n",
    "    text = re.sub(r'j k ', ' jk ', text)\n",
    "    text = re.sub(r' s ', ' ', text)\n",
    "    text = re.sub(r' yr ', ' year ', text)\n",
    "    text = re.sub(r' l g b t ', ' lgbt ', text)\n",
    "    \n",
    "    # Optionally, remove stop words\n",
    "    if remove_stopwords:\n",
    "        text = text.split()\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        text = [w for w in text if not w in stops]\n",
    "        text = \" \".join(text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the headlines\n",
    "cleaned_daily_headlines = []\n",
    "\n",
    "for headlines in daily_headlines:\n",
    "    cleaned_headlines = []\n",
    "    for headline in headlines:\n",
    "        cleaned_headlines.append(clean_text(headline))\n",
    "    cleaned_daily_headlines.append(cleaned_headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bitcoin Risks Falling to $2,900 if Market is Heading for Long-Term lower low',\n",
       " 'Here’s Why Bitcoin Didn’t Bottom at $3,800 According to a Top analyst',\n",
       " 'Bitcoin Sinks to $4,390 as Dow’s 1,000-Point Drop Risks Bigger breakdown',\n",
       " 'Bitcoin could soon be in the museum of illusions: ex Director-General ECB',\n",
       " 'Bitcoin Price Analysis: BTC’s 3-Day Consolidation Is Likely To End By Huge Move Very Soon',\n",
       " '‘Extreme Fear’ Grips Markets Despite Oversold Bitcoin Price Metrics',\n",
       " 'Bitcoin (BTC) Price Bottom Might Be Already In. Trader Explains Why',\n",
       " 'Bitcoin Trading Near Make-or-Break Levels: Can Bulls Make It?',\n",
       " 'Here’s How Bitcoin’s Market Cap Would Look Like in 3D',\n",
       " 'Bitcoin Fails to Jump $6,000, Top Analyst Warns Further Breakdown',\n",
       " '1 of BitMEX’s Most Profitable Traders Still Thinks Bitcoin Will Hit $30,000',\n",
       " 'Bitcoin Mempool Briefly Drops to Zero on Blockchain.\\u200bcom',\n",
       " 'Despite Bitcoin Price Dips, Crypto Is a Safe Haven in the Middle East',\n",
       " 'Bitcoin Price Tops $5.9K as Fed Cuts Interest Rates to 0%, Restarts QE']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_headlines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bitcoin risks falling $ 2 900 market heading long term lower low',\n",
       " 'here’s bitcoin didn’t bottom $ 3 800 according top analyst',\n",
       " 'bitcoin sinks $ 4 390 dow’s 1 000 point drop risks bigger breakdown',\n",
       " 'bitcoin could soon museum illusions ex director general ecb',\n",
       " 'bitcoin price analysis btc’s 3 day consolidation likely end huge move soon',\n",
       " '‘extreme fear’ grips markets despite oversold bitcoin price metrics',\n",
       " 'bitcoin btc price bottom might already trader explains',\n",
       " 'bitcoin trading near make break levels bulls make',\n",
       " 'here’s bitcoin’s market cap would look like 3d',\n",
       " 'bitcoin fails jump $ 6 000 top analyst warns breakdown',\n",
       " '1 bitmex’s profitable traders still thinks bitcoin hit $ 30000',\n",
       " 'bitcoin mempool briefly drops zero blockchain \\u200bcom',\n",
       " 'despite bitcoin price dips crypto safe middle east',\n",
       " 'bitcoin price tops $ 5 9k fed cuts interest rates 0 restarts qe']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_daily_headlines[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Glove word vectors of the vocabulary which is created externally\n",
    "csv_file = \"word_vectors.csv\"\n",
    "\n",
    "embeddings = {}\n",
    "\n",
    "df_word_vectors = pd.read_csv(csv_file)\n",
    "\n",
    "for row in df_word_vectors.iterrows():\n",
    "    word = row[1]['key']\n",
    "    vector = row[1]['vector']\n",
    "    \n",
    "    vector = vector[1:]\n",
    "    vector = vector[:-1]\n",
    "    \n",
    "    new_points = []\n",
    "    points = vector.split(', ')\n",
    "    \n",
    "    for point in points:\n",
    "        point = round(float(point), 4)\n",
    "        new_points.append(point)\n",
    "    \n",
    "    embeddings[word] = new_points\n",
    "    \n",
    "del df_word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12531\n"
     ]
    }
   ],
   "source": [
    "# Check if value matches len(vocab_to_int)\n",
    "print(len(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5617, -0.4218,  0.4806, -0.4225, -0.2679, -0.3209, -0.912 ,\n",
       "        -0.9096, -0.5675,  0.9415, -0.2629, -0.3466,  0.4338, -0.2826,\n",
       "         0.2644, -0.4312, -0.5574, -1.    , -0.9863,  0.6394,  0.9279,\n",
       "         0.7645, -0.9167,  0.5244,  0.7897,  0.8154,  0.978 ,  0.092 ,\n",
       "        -0.5521,  0.0411, -0.7062,  0.2137,  0.8611,  0.6348, -0.3065,\n",
       "         0.4463,  0.8689,  0.6724, -0.5826,  0.2383, -0.7589,  0.1618,\n",
       "        -0.2726,  0.9011,  0.2656,  0.2292, -0.5403, -0.7686, -0.4515,\n",
       "        -0.8293, -0.723 , -0.7331,  0.244 ,  0.4797,  0.8089, -0.3421,\n",
       "         0.3189,  0.9645,  0.6748,  0.4616, -0.5703,  0.0386, -0.4626,\n",
       "         0.7908, -0.2842, -0.4153, -0.1122,  0.5307, -0.8728, -0.089 ,\n",
       "        -0.9393,  0.7892, -0.6934, -0.9863, -0.3766,  0.9389, -0.8788,\n",
       "         0.3495, -0.8294, -0.5417, -0.9383,  0.1929,  0.552 ,  0.0729,\n",
       "         0.1723,  0.4606, -0.9398,  0.3593, -0.8251,  0.222 ,  0.5292,\n",
       "        -0.5941,  0.2026,  0.2118,  0.3753,  0.2143, -0.5235,  0.7716,\n",
       "        -0.084 , -0.7786,  0.9566,  0.63  ,  0.7954, -0.4825, -0.9149,\n",
       "        -0.2652, -0.4921,  0.9067,  0.4826, -0.7842,  0.5369, -0.8198,\n",
       "         0.3783, -0.3424,  0.351 ,  0.704 , -0.8847,  0.2893, -0.9688,\n",
       "        -0.7717,  0.7135, -0.4494,  0.6244, -0.2286, -0.1802, -0.9168,\n",
       "        -0.5652,  0.1074,  0.4714, -0.2232,  0.6124, -0.004 , -0.2348,\n",
       "        -0.35  , -0.8097,  0.0742,  0.7921,  0.1548, -0.6454,  0.25  ,\n",
       "         0.7847, -0.0097,  0.4713, -0.7562,  0.2922, -0.0074, -0.3924,\n",
       "        -0.7464,  0.9369, -0.7433,  0.4246,  0.0814, -0.9353, -0.1529,\n",
       "         0.4939, -0.2882, -0.8852, -0.7697,  0.552 ,  0.2727,  0.5367,\n",
       "        -0.9922, -0.9966,  0.1377, -0.6863,  0.4239,  0.1414,  0.5494,\n",
       "         0.4507,  0.1705, -0.2602, -0.4543, -0.2021, -0.0682,  0.4647,\n",
       "        -0.5901, -0.9549,  0.8206, -0.5568,  0.3215,  0.6186,  0.0838,\n",
       "         0.5552,  0.9688,  0.1555, -0.654 , -0.1344, -0.2583, -0.2643,\n",
       "        -0.1244, -0.6993, -0.8409, -0.21  , -0.7786,  0.9856, -0.2836,\n",
       "        -0.1657,  0.5501,  0.0902,  0.5478, -0.6907, -0.7673, -0.9829,\n",
       "        -0.5404,  0.5016,  0.5782,  0.7622, -0.3618,  0.7436,  0.2803,\n",
       "        -0.9165,  0.416 ,  0.7061,  0.244 ,  0.8143,  0.294 , -0.1192,\n",
       "        -0.1058,  0.6962,  0.5494, -0.545 ,  0.233 ,  0.2429,  0.6638,\n",
       "         0.2686,  0.3081,  0.679 ,  0.6837,  0.7352,  0.3028, -0.5325,\n",
       "        -0.7348, -0.8796,  0.4083,  0.7228,  0.412 , -0.4936,  0.2882,\n",
       "        -0.6749, -0.8779, -0.1108,  0.7419, -0.9872, -0.1962, -0.8908,\n",
       "        -0.0395,  0.7731,  0.96  , -0.9427, -0.7037,  0.3646,  0.1938,\n",
       "        -0.0023,  0.4318,  0.6813, -0.2836,  0.7777, -0.6999,  0.9528,\n",
       "        -0.0302, -0.2116, -0.9269,  0.4276, -0.5609,  0.5872, -0.5162,\n",
       "         0.7484, -0.3439,  0.0676, -0.6627,  0.9619, -0.0157, -0.5564,\n",
       "         0.581 ,  0.491 , -0.7577, -0.367 , -0.5862, -0.5347, -0.2391,\n",
       "         0.8407,  0.4257, -0.1865, -0.0501,  0.4001,  0.6581,  0.4714,\n",
       "         0.9232, -0.3081,  0.9762,  0.3443,  0.1448, -0.4906,  0.5087,\n",
       "        -0.5044, -0.2129,  0.278 , -0.4038, -0.5654, -0.838 ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_word_vector = embeddings['bitcoin']\n",
    "np.array(example_word_vector).reshape(1, len(example_word_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12531\n"
     ]
    }
   ],
   "source": [
    "# Check if value matches len(vocab_to_int)\n",
    "print(len(embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size of the vocabulary is 16089.\n"
     ]
    }
   ],
   "source": [
    "# Find the number of times each word was used and the size of the vocabulary\n",
    "word_counts = {}\n",
    "\n",
    "for daily_headlines in cleaned_daily_headlines:\n",
    "    for headline in daily_headlines:\n",
    "        for word in headline.split():\n",
    "            if word not in word_counts:\n",
    "                word_counts[word] = 1\n",
    "            else:\n",
    "                word_counts[word] += 1\n",
    "\n",
    "print(\"the size of the vocabulary is {}.\".format(len(word_counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the vocab that we will use to words\n",
    "vocab_to_int = {}\n",
    "\n",
    "value = 0\n",
    "threshold = 100\n",
    "for word, count in word_counts.items():\n",
    "    if count >= threshold or word in embeddings.keys():\n",
    "        vocab_to_int[word] = value\n",
    "        value += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Special tokens that will be added to our vocab\n",
    "codes = [\"<UNK>\",\"<PAD>\"]   \n",
    "\n",
    "# Add codes to vocab\n",
    "for code in codes:\n",
    "    vocab_to_int[code] = len(vocab_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert integers to words\n",
    "int_to_vocab = {}\n",
    "for word, value in vocab_to_int.items():\n",
    "    int_to_vocab[value] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12531"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = int_to_vocab.keys()\n",
    "len(list(keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'0': bitcoin\n",
      "'1': risks\n",
      "'2': falling\n",
      "'3': $\n",
      "'4': 2\n",
      "'5': 900\n",
      "'6': market\n",
      "'7': heading\n",
      "'8': long\n",
      "'9': term\n"
     ]
    }
   ],
   "source": [
    "print_dictionary(int_to_vocab, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'bitcoin': 0\n",
      "'risks': 1\n",
      "'falling': 2\n",
      "'$': 3\n",
      "'2': 4\n",
      "'900': 5\n",
      "'market': 6\n",
      "'heading': 7\n",
      "'long': 8\n",
      "'term': 9\n"
     ]
    }
   ],
   "source": [
    "print_dictionary(vocab_to_int, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12531"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size = len(vocab_to_int)\n",
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Unique Words: 16089\n",
      "Number of Words we will use: 12531\n",
      "Percent of Words we will use: 77.89%\n"
     ]
    }
   ],
   "source": [
    "usage_ratio = round(len(vocab_to_int) / len(word_counts),4)*100\n",
    "\n",
    "print(\"Total Number of Unique Words:\", len(word_counts))\n",
    "print(\"Number of Words we will use:\", len(vocab_to_int))\n",
    "print(\"Percent of Words we will use: {}%\".format(usage_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the text from words to integers\n",
    "# If word is not in vocab, replace it with <UNK> (unknown)\n",
    "\n",
    "total_word_count = 0\n",
    "unknown_word_count = 0\n",
    "\n",
    "headlines_to_int = []\n",
    "\n",
    "for headlines in cleaned_daily_headlines:\n",
    "    daily_headlines_to_int = []\n",
    "    for headline in headlines:\n",
    "        headline_to_int = []\n",
    "        for word in headline.split():\n",
    "            total_word_count += 1\n",
    "            if word in vocab_to_int:\n",
    "                headline_to_int.append(vocab_to_int[word])\n",
    "            else:\n",
    "                headline_to_int.append(vocab_to_int['<UNK>'])\n",
    "                unknown_word_count += 1\n",
    "        daily_headlines_to_int.append(headline_to_int)\n",
    "    headlines_to_int.append(daily_headlines_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in headlines: 167512\n",
      "Total number of UNKs in headlines: 8332\n",
      "Percent of words that are UNK: 4.97%\n"
     ]
    }
   ],
   "source": [
    "unknown_percentage  = round(unknown_word_count/total_word_count, 4) * 100\n",
    "print(\"Total number of words in headlines:\", total_word_count)\n",
    "print(\"Total number of UNKs in headlines:\", unknown_word_count)\n",
    "print(\"Percent of words that are UNK: {}%\".format(unknown_percentage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
       " [12529, 0, 12529, 12, 3, 13, 14, 15, 16, 17],\n",
       " [0, 18, 3, 19, 20, 12529, 21, 22, 23, 24, 1, 25, 26],\n",
       " [0, 27, 28, 29, 30, 31, 32, 33, 34],\n",
       " [0, 35, 36, 12529, 13, 37, 38, 39, 40, 41, 42, 28],\n",
       " [12529, 12529, 43, 44, 45, 46, 0, 35, 47],\n",
       " [0, 48, 35, 12, 49, 50, 51, 52],\n",
       " [0, 53, 54, 55, 56, 57, 58, 55],\n",
       " [12529, 59, 6, 60, 61, 62, 63, 64],\n",
       " [0, 65, 66, 3, 67, 22, 16, 17, 68, 26],\n",
       " [21, 12529, 69, 70, 71, 72, 0, 73, 3, 74],\n",
       " [0, 75, 76, 77, 78, 79, 12529],\n",
       " [45, 0, 35, 80, 81, 82, 83, 84],\n",
       " [0, 35, 85, 3, 86, 87, 88, 89, 90, 91, 92, 93, 94]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines_to_int[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the length of headlines\n",
    "lengths = []\n",
    "for headlines in headlines_to_int:\n",
    "    for headline in headlines:\n",
    "        lengths.append(len(headline))\n",
    "\n",
    "# Create a dataframe so that the values can be inspected\n",
    "lengths = pd.DataFrame(lengths, columns=['counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17047.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.826480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.030185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             counts\n",
       "count  17047.000000\n",
       "mean       9.826480\n",
       "std        3.030185\n",
       "min        1.000000\n",
       "25%        8.000000\n",
       "50%        9.000000\n",
       "75%       12.000000\n",
       "max       21.000000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the lenght of a day's news to 200 words, and the length of any headline to 16 words.\n",
    "# These values are chose to not have an excessively long training time and \n",
    "# balance the number of headlines used and the number of words from each headline.\n",
    "\n",
    "max_headline_length = 16\n",
    "max_daily_length = 200\n",
    "padded_daily_headlines = []\n",
    "\n",
    "for daily_headlines in headlines_to_int:\n",
    "    padded_headlines = []\n",
    "    for headline in daily_headlines:\n",
    "        \n",
    "        # Add headline if it is less than max_length\n",
    "        if len(headline) <= max_headline_length:\n",
    "            for word in headline:\n",
    "                padded_headlines.append(word)\n",
    "                \n",
    "        # Limit headline if it is more than max_length\n",
    "        else:\n",
    "            headline = headline[:max_headline_length]\n",
    "            for word in headline:\n",
    "                padded_headlines.append(word)\n",
    "    \n",
    "    # Pad padded_headlines if they are less than max_daily_length\n",
    "    if(len(padded_headlines) < max_daily_length):\n",
    "        pad = vocab_to_int['<PAD>']\n",
    "        for i in range(max_daily_length - len(padded_headlines)):\n",
    "            padded_headlines.append(pad)\n",
    "            \n",
    "    # Limit padded_headlines if they are more than max_daily_length\n",
    "    else:\n",
    "        padded_headlines = padded_headlines[:max_daily_length]\n",
    "        \n",
    "    \n",
    "    padded_daily_headlines.append(padded_headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1128, 200)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_daily_headlines = np.reshape(padded_daily_headlines, (len(padded_daily_headlines), max_daily_length))\n",
    "padded_daily_headlines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  527,  7227,   103,   156,    61,    55,  4709, 12529,   789,\n",
       "        6633,    50,  9316,  1450, 12529,  7385,   174,  1231,  4096,\n",
       "        1269,  4950,   369,  9317,  3983,    49, 12530, 12530, 12530,\n",
       "       12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530,\n",
       "       12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530,\n",
       "       12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530,\n",
       "       12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530,\n",
       "       12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530,\n",
       "       12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530,\n",
       "       12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530,\n",
       "       12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530,\n",
       "       12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530,\n",
       "       12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530,\n",
       "       12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530,\n",
       "       12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530,\n",
       "       12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530,\n",
       "       12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530,\n",
       "       12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530,\n",
       "       12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530,\n",
       "       12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530,\n",
       "       12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530,\n",
       "       12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530,\n",
       "       12530, 12530])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_daily_headlines[750]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Embedding layer weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to use 300 features for embedding dimensions to match Glove's vectors\n",
    "embedding_dimension = 300\n",
    "\n",
    "vocabulary_size = len(vocab_to_int)\n",
    "\n",
    "# Create a matrix with default values of zero\n",
    "word_vectors = np.zeros((vocabulary_size, embedding_dimension))\n",
    "\n",
    "for word, i in vocab_to_int.items():\n",
    "    if word in embeddings.keys():\n",
    "        word_vectors[i] = embeddings[word]\n",
    "    else:\n",
    "        # If word not in GloVe, create a random embedding for it\n",
    "        random_word_vector = np.array(np.random.uniform(-1.0, 1.0, embedding_dimension))\n",
    "        glove_word_vectors[word] = random_word_vector\n",
    "        word_vectors[i] = random_word_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Preparing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = df_price['change'].apply(lambda x: 1 if x>0 else 0)\n",
    "y = label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1128, 1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(y).reshape((y.size, 1))\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets.\n",
    "# Validating data will be created during training.\n",
    "test_size=0.20\n",
    "\n",
    "(X_train, X_test) = train_test_split(padded_daily_headlines, \n",
    "                                               test_size = test_size, \n",
    "                                               random_state = 2)\n",
    "\n",
    "(y_train, y_test) = train_test_split(y, \n",
    "                                     test_size=test_size, \n",
    "                                     random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12529,    12,  1617,  2081,  6588,   646,  1112, 12529,  2980,\n",
       "         254,    48, 12529,   202,     0,   149,   108,   109,  6589,\n",
       "         624, 12529,    17,  6176,     0,  1089,  4831,  1743,   515,\n",
       "           3,    86,    14,    16,  1171,  1782,   580,     0,   677,\n",
       "         605,     0,   785,  1356,  1791,   689,   827,  4032,  3567,\n",
       "        3858,    35,    36,   223,    13,    27,    48,    35,    73,\n",
       "           3,    21,    86,   384,  5375,  6590,  4785,   671,     0,\n",
       "          48,   983,   516,   449,     3,    86,   343,     6,    58,\n",
       "        6591,     0,    35,  4474,     3,    86,   343,  1086,   416,\n",
       "        4760, 12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530,\n",
       "       12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530,\n",
       "       12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530,\n",
       "       12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530,\n",
       "       12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530,\n",
       "       12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530,\n",
       "       12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530,\n",
       "       12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530,\n",
       "       12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530,\n",
       "       12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530,\n",
       "       12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530,\n",
       "       12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530,\n",
       "       12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530, 12530,\n",
       "       12530, 12530])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('./train_and_test/X_train.txt', X_train, delimiter=',')\n",
    "np.savetxt('./train_and_test/X_test.txt', X_test, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('./train_and_test/y_train.txt', y_train, delimiter=',')\n",
    "np.savetxt('./train_and_test/y_test.txt', y_test, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Mert\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras.utils import plot_model\n",
    "model = load_model('model-0.6238937973976135.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 200, 300)          3759300   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 200, 64)           153664    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 50, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 50, 128)           131200    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 12, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 4,192,389\n",
      "Trainable params: 4,192,389\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_model(model, show_shapes=True, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226/226 [==============================] - 2s 9ms/step\n",
      "Test score: 0.24544845732439935\n",
      "Test accuracy: 0.6238937973976135\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import library to check other metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix\n",
      "[[57 50]\n",
      " [35 84]]\n"
     ]
    }
   ],
   "source": [
    "matrix = confusion_matrix(y_test, predictions.round())\n",
    "print('confusion_matrix')\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.53      0.57       107\n",
      "           1       0.63      0.71      0.66       119\n",
      "\n",
      "    accuracy                           0.62       226\n",
      "   macro avg       0.62      0.62      0.62       226\n",
      "weighted avg       0.62      0.62      0.62       226\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, predictions.round())\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
